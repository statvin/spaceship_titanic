{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60123e8d",
   "metadata": {},
   "source": [
    "## 1. Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff04b12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588409a0",
   "metadata": {},
   "source": [
    "## 2. Importando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bd31283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo carregado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv('../Datasets/train.csv')\n",
    "    print(\"Arquivo carregado com sucesso!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Erro: Arquivo 'train.csv' não encontrado. Verifique o caminho do arquivo.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3544b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "   Transported  \n",
       "0        False  \n",
       "1         True  \n",
       "2        False  \n",
       "3        False  \n",
       "4         True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3d3c0b",
   "metadata": {},
   "source": [
    "## 3. Limpeza e Separação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c8f5dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Bloco 3: Tratando 'Cabin' ---\n",
      "Colunas 'Deck', 'Num' e 'Side' criadas.\n",
      "  Deck  Num Side\n",
      "0    B    0    P\n",
      "1    F    0    S\n",
      "2    A    0    S\n",
      "3    A    0    S\n",
      "4    F    1    S\n"
     ]
    }
   ],
   "source": [
    "# Limpeza - Engenharia de Features (Cabin)\n",
    "\n",
    "print(\"--- Bloco 3: Tratando 'Cabin' ---\")\n",
    "\n",
    "# 1. Preencher valores NaN na coluna 'Cabin'\n",
    "df['Cabin'] = df['Cabin'].fillna('U/0/U')\n",
    "\n",
    "# 2. Dividir a coluna 'Cabin' em 3 novas colunas\n",
    "# Removi o 'try/except' para vermos o erro se ele acontecer aqui\n",
    "df[['Deck', 'Num', 'Side']] = df['Cabin'].str.split('/', expand=True)\n",
    "\n",
    "# 3. Converter 'Num' para tipo numérico (e preencher NaN se houver)\n",
    "df['Num'] = pd.to_numeric(df['Num'], errors='coerce') # 'coerce' transforma erros em NaN\n",
    "df['Num'] = df['Num'].fillna(df['Num'].median()) # Preenche NaN criados\n",
    "\n",
    "print(\"Colunas 'Deck', 'Num' e 'Side' criadas.\")\n",
    "print(df[['Deck', 'Num', 'Side']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac24f08",
   "metadata": {},
   "source": [
    "## 4. Limpeza - Preenchimento de valores ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dff19aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Bloco 4: Preenchendo NaNs restantes ---\n",
      "Valores Ausentes preenchidos.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\viras\\AppData\\Local\\Temp\\ipykernel_32160\\2737623566.py:19: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(moda)\n"
     ]
    }
   ],
   "source": [
    "# Limpeza - Preenchendo Valores Ausentes (NaN)\n",
    "\n",
    "print(\"--- Bloco 4: Preenchendo NaNs restantes ---\")\n",
    "\n",
    "# 1. Definir colunas\n",
    "colunas_numericas = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'Num']\n",
    "colunas_categoricas = ['HomePlanet', 'CryoSleep', 'VIP', 'Deck', 'Side']\n",
    "\n",
    "# 2. Preencher numéricas com MEDIANA\n",
    "for col in colunas_numericas:\n",
    "    if col in df.columns:\n",
    "        mediana = df[col].median()\n",
    "        df[col] = df[col].fillna(mediana)\n",
    "\n",
    "# 3. Preencher categóricas com MODA (valor mais comum)\n",
    "for col in colunas_categoricas:\n",
    "    if col in df.columns:\n",
    "        moda = df[col].mode()[0]\n",
    "        df[col] = df[col].fillna(moda)\n",
    "\n",
    "print(\"Valores Ausentes preenchidos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eedcbb6",
   "metadata": {},
   "source": [
    "## 5. Limpeza - Enconding e Finalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "beea3963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Bloco 5: Encoding ---\n",
      "Colunas inúteis removidas.\n",
      "Colunas booleanas convertidas.\n",
      "Forçando One-Hot Encoding em: ['HomePlanet', 'Deck', 'Side']\n",
      "\n",
      "--- Limpeza Concluída. Verificação Final: ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8693 entries, 0 to 8692\n",
      "Data columns (total 22 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   CryoSleep          8693 non-null   bool   \n",
      " 1   Age                8693 non-null   float64\n",
      " 2   VIP                8693 non-null   bool   \n",
      " 3   RoomService        8693 non-null   float64\n",
      " 4   FoodCourt          8693 non-null   float64\n",
      " 5   ShoppingMall       8693 non-null   float64\n",
      " 6   Spa                8693 non-null   float64\n",
      " 7   VRDeck             8693 non-null   float64\n",
      " 8   Transported        8693 non-null   bool   \n",
      " 9   Num                8693 non-null   int64  \n",
      " 10  HomePlanet_Europa  8693 non-null   bool   \n",
      " 11  HomePlanet_Mars    8693 non-null   bool   \n",
      " 12  Deck_B             8693 non-null   bool   \n",
      " 13  Deck_C             8693 non-null   bool   \n",
      " 14  Deck_D             8693 non-null   bool   \n",
      " 15  Deck_E             8693 non-null   bool   \n",
      " 16  Deck_F             8693 non-null   bool   \n",
      " 17  Deck_G             8693 non-null   bool   \n",
      " 18  Deck_T             8693 non-null   bool   \n",
      " 19  Deck_U             8693 non-null   bool   \n",
      " 20  Side_S             8693 non-null   bool   \n",
      " 21  Side_U             8693 non-null   bool   \n",
      "dtypes: bool(15), float64(6), int64(1)\n",
      "memory usage: 602.9 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Bloco 5: Encoding ---\")\n",
    "\n",
    "# 1. Remover colunas inúteis\n",
    "colunas_para_remover = ['PassengerId', 'Name', 'Cabin', 'Destination']\n",
    "df = df.drop(columns=[col for col in colunas_para_remover if col in df.columns])\n",
    "print(\"Colunas inúteis removidas.\")\n",
    "\n",
    "# 2. Converter Booleanos para 0/1\n",
    "if 'CryoSleep' in df.columns:\n",
    "    df['CryoSleep'] = df['CryoSleep'].map({True: True, False: False, 'True': True, 'False': False}).astype(bool)\n",
    "if 'VIP' in df.columns:\n",
    "    df['VIP'] = df['VIP'].map({True: True, False: False, 'True': True, 'False': False}).astype(bool)\n",
    "df['Transported'] = df['Transported'].astype(bool)\n",
    "print(\"Colunas booleanas convertidas.\")\n",
    "\n",
    "# 3. Aplicar One-Hot Encoding (A CORREÇÃO)\n",
    "# Vamos forçar a codificação das colunas que SABEMOS que são texto,\n",
    "# sem verificar 'dtype' ou qualquer outra coisa.\n",
    "colunas_para_codificar = ['HomePlanet', 'Deck', 'Side']\n",
    "\n",
    "# Filtra apenas as que realmente existem no dataframe\n",
    "colunas_existentes = [col for col in colunas_para_codificar if col in df.columns]\n",
    "\n",
    "print(f\"Forçando One-Hot Encoding em: {colunas_existentes}\")\n",
    "df = pd.get_dummies(df, columns=colunas_existentes, drop_first=True)\n",
    "\n",
    "print(\"\\n--- Limpeza Concluída. Verificação Final: ---\")\n",
    "# A saída do .info() NÃO PODE TER NENHUM 'object'\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412d4e15",
   "metadata": {},
   "source": [
    "## 6. Separando X e y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "577ffeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Separando dados de Treino e Teste ---\n",
      "Dados de treino (X_treino): (6954, 21)\n",
      "Dados de teste (X_teste): (1739, 21)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"--- Separando dados de Treino e Teste ---\")\n",
    "y = df['Transported']\n",
    "X = df.drop(columns=['Transported'])\n",
    "\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Dados de treino (X_treino): {X_treino.shape}\")\n",
    "print(f\"Dados de teste (X_teste): {X_teste.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6404f7",
   "metadata": {},
   "source": [
    "## 7. StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bf2e23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando Normalização ---\n",
      "Dados de treino e teste normalizados com sucesso.\n"
     ]
    }
   ],
   "source": [
    "#  Normalização dos Dados\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(\"--- Iniciando Normalização ---\")\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_treino)\n",
    "\n",
    "X_treino_scaled = scaler.transform(X_treino)\n",
    "X_teste_scaled = scaler.transform(X_teste)\n",
    "\n",
    "print(\"Dados de treino e teste normalizados com sucesso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0650409",
   "metadata": {},
   "source": [
    "## 8. Modelo 1: Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1b909cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Treinando Modelo 1: Regressão Logística ---\n",
      "\n",
      "--- Resultados da Regressão Logística ---\n",
      "Acurácia: 0.7832\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.80      0.75      0.77       861\n",
      "        True       0.77      0.82      0.79       878\n",
      "\n",
      "    accuracy                           0.78      1739\n",
      "   macro avg       0.78      0.78      0.78      1739\n",
      "weighted avg       0.78      0.78      0.78      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Modelo 1 - Regressão Logística\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(\"--- Treinando Modelo 1: Regressão Logística ---\")\n",
    "modelo_lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "modelo_lr.fit(X_treino_scaled, y_treino)\n",
    "y_pred_lr = modelo_lr.predict(X_teste_scaled)\n",
    "\n",
    "acuracia_lr = accuracy_score(y_teste, y_pred_lr)\n",
    "print(f\"\\n--- Resultados da Regressão Logística ---\")\n",
    "print(f\"Acurácia: {acuracia_lr:.4f}\")\n",
    "print(classification_report(y_teste, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e10229",
   "metadata": {},
   "source": [
    "## 9. Modelo 2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34c1c9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Treinando Modelo 2: Random Forest ---\n",
      "\n",
      "--- Resultados do Random Forest (Base) ---\n",
      "Acurácia: 0.7872\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.77      0.81      0.79       861\n",
      "        True       0.80      0.76      0.78       878\n",
      "\n",
      "    accuracy                           0.79      1739\n",
      "   macro avg       0.79      0.79      0.79      1739\n",
      "weighted avg       0.79      0.79      0.79      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Modelo 2 - Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "print(\"--- Treinando Modelo 2: Random Forest ---\")\n",
    "modelo_rf = RandomForestClassifier(random_state=42)\n",
    "# Usando X_treino (NÃO normalizado)\n",
    "modelo_rf.fit(X_treino, y_treino)\n",
    "\n",
    "y_pred_rf = modelo_rf.predict(X_teste)\n",
    "\n",
    "acuracia_rf = accuracy_score(y_teste, y_pred_rf)\n",
    "print(f\"\\n--- Resultados do Random Forest (Base) ---\")\n",
    "print(f\"Acurácia: {acuracia_rf:.4f}\")\n",
    "print(classification_report(y_teste, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63efcbe2",
   "metadata": {},
   "source": [
    "## 10. Otimizando hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e341a171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando Otimização (GridSearchCV) ---\n",
      "AVISO: Isso pode demorar alguns minutos...\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
      "\n",
      "Otimização Concluída!\n",
      "Melhores Parâmetros: {'max_depth': 10, 'n_estimators': 100}\n",
      "\n",
      "--- Resultados do Random Forest (OTIMIZADO) ---\n",
      "Acurácia Otimizada: 0.7953\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.81      0.77      0.79       861\n",
      "        True       0.78      0.82      0.80       878\n",
      "\n",
      "    accuracy                           0.80      1739\n",
      "   macro avg       0.80      0.80      0.80      1739\n",
      "weighted avg       0.80      0.80      0.80      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Otimização de Hiperparâmetros (GridSearchCV)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "print(\"--- Iniciando Otimização (GridSearchCV) ---\")\n",
    "print(\"AVISO: Isso pode demorar alguns minutos...\")\n",
    "\n",
    "# Parâmetros (simplificado para ser MAIS RÁPIDO)\n",
    "parametros = {\n",
    "    'n_estimators': [100],  # Apenas 100\n",
    "    'max_depth': [10, 20]   # Apenas 2 profundidades\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
    "                           param_grid=parametros,\n",
    "                           cv=2, # cv=2 (MAIS RÁPIDO)\n",
    "                           n_jobs=-1,\n",
    "                           scoring='accuracy',\n",
    "                           verbose=1)\n",
    "\n",
    "grid_search.fit(X_treino, y_treino)\n",
    "\n",
    "print(\"\\nOtimização Concluída!\")\n",
    "print(f\"Melhores Parâmetros: {grid_search.best_params_}\")\n",
    "\n",
    "melhor_rf = grid_search.best_estimator_\n",
    "y_pred_rf_otimizado = melhor_rf.predict(X_teste)\n",
    "acuracia_rf_otimizado = accuracy_score(y_teste, y_pred_rf_otimizado)\n",
    "\n",
    "print(f\"\\n--- Resultados do Random Forest (OTIMIZADO) ---\")\n",
    "print(f\"Acurácia Otimizada: {acuracia_rf_otimizado:.4f}\")\n",
    "print(classification_report(y_teste, y_pred_rf_otimizado))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bffb08",
   "metadata": {},
   "source": [
    "## 11. Respostas finais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabe67f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Comparação dos Modelos ---\n",
      "Acurácia Regressão Logística: 0.7832\n",
      "Acurácia Random Forest (Base): 0.7872\n",
      "Acurácia Random Forest (Otimizado): 0.7953\n",
      "\n",
      "\n",
      "--- RESPOSTAS PARA O PROFESSOR ---\n",
      "\n",
      "1. Meu modelo resolve adequadamente o problema proposto?\n",
      "Sim. O objetivo era prever se um passageiro seria 'Transportado' ou não. Nosso modelo final (Random Forest Otimizado) alcançou uma acurácia de 79.53%, o que significa que ele acerta a previsão para quase 79 em cada 100 passageiros. Isso é significativamente melhor do que um palpite aleatório (50%).\n",
      "\n",
      "2. Meu modelo pode ser colocado em produção?\n",
      "Sim, o modelo pode ser colocado em produção. O fluxo de 'pipeline' está bem definido: os novos dados (passageiros) precisariam passar pelo *exatamente* mesmo tratamento que fizemos (separação da 'Cabin', preenchimento de 'NaNs' com mediana/moda, e One-Hot Encoding) antes de serem enviados ao modelo 'melhor_rf.predict()'. A acurácia de 79.53% é considerada robusta para este problema.\n"
     ]
    }
   ],
   "source": [
    "# Comparação Final e Respostas\n",
    "\n",
    "print(\"--- Comparação dos Modelos ---\")\n",
    "# Vamos garantir que as variáveis existem caso algum bloco falhe\n",
    "try:\n",
    "    print(f\"Acurácia Regressão Logística: {acuracia_lr:.4f}\")\n",
    "    print(f\"Acurácia Random Forest (Base): {acuracia_rf:.4f}\")\n",
    "    print(f\"Acurácia Random Forest (Otimizado): {acuracia_rf_otimizado:.4f}\")\n",
    "    melhor_acuracia = acuracia_rf_otimizado\n",
    "except NameError:\n",
    "    print(\"ERRO: Um dos modelos falhou em treinar. Não é possível comparar.\")\n",
    "    melhor_acuracia = 0 # Valor padrão para evitar mais erros\n",
    "\n",
    "print(\"\\n1. Meu modelo resolve adequadamente o problema proposto?\")\n",
    "print(f\"Sim. O objetivo era prever se um passageiro seria 'Transportado' ou não. \"\n",
    "      f\"Nosso modelo final (Random Forest Otimizado) alcançou uma acurácia de {melhor_acuracia:.2%}, \"\n",
    "      f\"o que significa que ele acerta a previsão para quase {int(melhor_acuracia*100)} em cada 100 passageiros. \"\n",
    "      f\"Isso é significativamente melhor do que um palpite aleatório (50%).\")\n",
    "\n",
    "print(\"\\n2. Meu modelo pode ser colocado em produção?\")\n",
    "print(f\"Sim, o modelo pode ser colocado em produção. O fluxo de 'pipeline' está bem definido: \"\n",
    "      f\"os novos dados (passageiros) precisariam passar pelo *exatamente* mesmo tratamento \"\n",
    "      f\"que fizemos (separação da 'Cabin', preenchimento de 'NaNs' com mediana/moda, e One-Hot Encoding) \"\n",
    "      f\"antes de serem enviados ao modelo 'melhor_rf.predict()'. A acurácia de {melhor_acuracia:.2%} \"\n",
    "      f\"é considerada robusta para este problema.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f03664",
   "metadata": {},
   "source": [
    "## 12. Conclusão\n",
    "\n",
    "Este projeto teve como objetivo desenvolver um modelo de Machine Learning de ponta a ponta, utilizando o dataset \"Spaceship Titanic\" do Kaggle. O problema central era de classificação binária: prever se um passageiro seria \"transportado\" (a variável alvo Transported) com base em seus dados pessoais e de viagem.\n",
    "\n",
    "O processo seguiu todas as etapas fundamentais de um fluxo de trabalho de ciência de dados:\n",
    "\n",
    "1) Análise Exploratória e Limpeza de Dados: O dataset foi carregado e inspecionado. Identificamos uma quantidade significativa de valores ausentes (NaN) em colunas críticas como Age, HomePlanet, CryoSleep e Cabin. Estes valores foram tratados por imputação, usando a mediana para dados numéricos e a moda (valor mais frequente) para dados categóricos.\n",
    "\n",
    "2) Engenharia de Features: A coluna Cabin foi processada e dividida em três novas features mais informativas: Deck, Num e Side, o que permitiu ao modelo capturar melhor a localização física dos passageiros. Colunas textuais irrelevantes para a previsão, como Name, PassengerId e Destination, foram removidas.\n",
    "\n",
    "3) Pré-processamento: Todas as features categóricas restantes (HomePlanet, Deck, Side) foram transformadas em representações numéricas através do One-Hot Encoding. Os dados booleanos (CryoSleep, VIP) foram convertidos para inteiros (0/1).\n",
    "\n",
    "4) Seleção de Métrica: A Acurácia (Accuracy) foi escolhida como a métrica principal de avaliação, pois o dataset apresentou um bom balanceamento entre as duas classes (transportados e não transportados).\n",
    "\n",
    "Conforme solicitado nas instruções, dois estimadores foram comparados:\n",
    "\n",
    "Modelo 1: Regressão Logística: Após a normalização dos dados com StandardScaler, este modelo serviu como nossa baseline, alcançando uma acurácia de 78.32%.\n",
    "\n",
    "Modelo 2: Random Forest: Este modelo, baseado em árvores de decisão, obteve um resultado ligeiramente superior em sua forma base, com 78.72% de acurácia.\n",
    "\n",
    "Para atender ao requisito de otimização, aplicamos um GridSearchCV ao Random Forest. Ao testar diferentes hiperparâmetros (max_depth e n_estimators), conseguimos encontrar uma configuração otimizada que elevou a performance final do modelo para 79.53% de acurácia nos dados de teste.\n",
    "\n",
    "Este resultado confirma que o modelo de Random Forest Otimizado não apenas resolve o problema proposto com uma precisão significativamente superior à de um palpite aleatório, mas também estabelece um pipeline de tratamento de dados claro e replicável. Isso valida sua viabilidade para uma eventual implantação em produção, onde novos dados poderiam passar pelo mesmo processo de limpeza e transformação antes de serem enviados ao modelo para previsão."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
